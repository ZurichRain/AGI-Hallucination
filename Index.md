# Definition for AGI Hallucination
## Image-Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Woodpecker: Hallucination Correction for Multimodal Large Language Models](https://arxiv.org/pdf/2310.16045.pdf) | Shukang Yin ||
| 2019 | ArXiv | [Object Hallucination in Image Captioning](https://arxiv.org/pdf/1809.02156.pdf) | Anna Rohrbach ||
| 2023 | ArXiv | [GPT-4V(ision) as A Social Media Analysis Engine](https://arxiv.org/pdf/2311.07547.pdf) | Hanjia Lyu ||



## Video-Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2022 | ACCV | [Thinking Hallucination for Video Captioning](https://arxiv.org/pdf/2209.13853.pdf) | Nasib Ullah | 缓解Object Hallucination和Action Hallucination，提出一个 new metric COAHA 来综合评估这两种幻觉的程度 |
| 2022 | ArXiv | [Audio-visual video face hallucination with frequency supervision and cross modality support by speech based lip reading loss](https://arxiv.org/pdf/2211.10883.pdf) | Shailza Sharma ||
| 2022 | ArXiv | [Efficient Human Vision Inspired Action Recognition Using Adaptive Spatiotemporal Sampling](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10236596) | Khoi-Nguyen C. Mac | pre-scans the global scene context at low-resolution and decides to skip or request high-resolution features at salient regions for further processing. Based on a pre-scanned features, the temporal sampler decides whether to process the frame fully (Full model), or skip to the frame and propagate past information (bottom block). The spatial sampler in turns select RoIs from high-res input to augment the features with low-res inputs.  |
| 2022 | ArXiv | [Video Question Answering: Datasets, Algorithms and Challenges](https://arxiv.org/pdf/2203.01225.pdf) | Yaoyao Zhong | fine-grained to coarsegrained in both temporal and spatial domains ， information from noisy web-scale visiontext data , multi-step reasoning |
| 2023 | ArXiv | [RETRIEVAL-BASED VIDEO LANGUAGE MODEL FOR EFFICIENT LONG VIDEO QUESTION ANSWERING](https://arxiv.org/pdf/2312.04931.pdf) | Jiaqi Xu | long video and long text can introduces noise to the video QA process |




## 3D Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2022 | ACCV | [PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision](https://arxiv.org/pdf/2203.15625.pdf) | Kehong Gong ||
| 2014 | IEEE | [3D Face Hallucination from a Single Depth Frame](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7035806) | Shu Liang ||
| 2022 | AAAI | [Texture Generation Using Dual-Domain Feature Flow with Multi-View Hallucinations](https://ojs.aaai.org/index.php/AAAI/article/view/19895) | Seunggyu Chang ||



## Audio Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2022 | IEEE | [Hallucination of Speech Recognition Errors With Sequence to Sequence Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9693404) | Prashant Serai | They present novel end-to-end models to directly predict hallucinated ASR word sequence outputs, conditioning on an input word sequence as well as a corresponding phoneme sequence. |
| 2023 | ArXiv | [PARAMETER EFFICIENT AUDIO CAPTIONING WITH FAITHFUL GUIDANCE USING AUDIO-TEXT SHARED LATENT REPRESENTATION](https://arxiv.org/pdf/2309.03340.pdf) | Arvind Krishna Sridhar |  propose a data augmentation technique for generating hallucinated audio captions and show that similarity based on an audio-text shared latent space is suitable for detecting hallucination. and  propose a parameter efficient inference time faithful decoding algorithm that enables smaller audio captioning models with performance equivalent to larger models trained with more data |
| 2023 | ArXiv | [Factual Consistency Oriented Speech Recognition](https://arxiv.org/pdf/2302.12369.pdf) | Naoyuki Kanda | This paper presents a novel optimization framework for automatic speech recognition (ASR) with the aim of reducing hallucinations produced by an ASR model.  The proposed framework optimizes the ASR model to maximize an expected factual consistency score between ASR hypotheses and groundtruth transcriptions, where the factual consistency score is computed by a separately trained estimator. |
| 2023 | ArXiv | [LP-MusicCaps: LLM-BASED PSEUDO MUSIC CAPTIONING](https://arxiv.org/pdf/2307.16372.pdf) | SeungHeon Doh ||
| 2020 | ArXiv | [Identifying Audio Adversarial Examples via Anomalous Patern Detection](https://arxiv.org/pdf/2002.05463.pdf) | Victor Akinwande | Audio processing models based on deep neural networks are susceptible to adversarial attacks even when the adversarial audio waveform is 99.9% similar to a benign sample , propose a method to detect audio adversarial samples. |
| 2023 | ArXiv | [LISTEN, THINK, AND UNDERSTAND](https://arxiv.org/pdf/2305.10790.pdf) | Yuan Gong | created a new OpenAQA-5M dataset consisting of 1.9 million closed-ended and 3.7 million open-ended, diverse (audio, question, answer) tuples, and have used an autoregressive training framework with a perception-to-understanding curriculum. LTU demonstrates strong performance and generalization ability on conventional audio tasks such as classification and captioning , can greatly mitigate the hallucination issue. |





## Language Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models](https://arxiv.org/pdf/2309.01219.pdf) | Yue Zhang ||
| 2022 | ArXiv | [Survey of Hallucination in Natural Language Generation](https://arxiv.org/pdf/2202.03629.pdf) | ZIWEI JI ||
| 2023 | ArXiv | [Theory of Hallucinations based on Equivariance](https://arxiv.org/pdf/2312.14504.pdf) | Hisaichi Shibata ||
| 2023 | ArXiv | [Cognitive Mirage: A Review of Hallucinations in Large Language Models](https://arxiv.org/pdf/2309.06794.pdf) | Hongbin Ye ||
| 2023 | ArXiv | [Factuality Challenges in the Era of Large Language Models](https://arxiv.org/pdf/2310.05189.pdf) | Isabelle Augenstein ||






## Robotic & Agent Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Learning Perceptual Hallucination for Multi-Robot Navigation in Narrow Hallways](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161327) | Jin-Soo Park ||
| 2023 | ArXiv | [Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners](https://arxiv.org/pdf/2307.01928.pdf) | Allen Z. Ren ||
| 2021 | ArXiv | [Toward Agile Maneuvers in Highly Constrained Spaces: Learning from Hallucination](https://arxiv.org/pdf/2007.14479.pdf) | Xuesu Xiao ||
| 2023 | ArXiv | [LARGE LANGUAGE MODELS AS GENERALIZABLE POLICIES FOR EMBODIED TASKS](https://arxiv.org/pdf/2310.17722.pdf) | Andrew Szot ||




# Emergence for AGI Hallucination
## Data Distribution in the Training Stage
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2021 | ArXiv | [How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN](https://arxiv.org/pdf/2111.09509.pdf) | R. Thomas McCoy | |
| 2023 | ArXiv | [Explanation Shift: How Did the Distribution Shift Impact the Model?](https://arxiv.org/pdf/2303.08081.pdf) | Carlos Mougan | |
| 2023 | ArXiv | [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf) | Hyung Won Chung | |
| 2023 | ArXiv | [HOW ABILITIES IN LARGE LANGUAGE MODELS ARE AFFECTED BY SUPERVISED FINE-TUNING DATA COMPOSITION](https://arxiv.org/pdf/2310.05492.pdf) | Guanting Dong | |
| 2023 | ArXiv | [On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?](https://arxiv.org/pdf/2204.07931.pdf) | Nouha Dziri | |
| 2020 | ArXiv | [Data augmentation techniques for the Video Question Answering task](https://arxiv.org/pdf/2008.09849.pdf) | Alex Falcon | |
| 2023 | ArXiv | [Sources of Hallucination by Large Language Models on Inference Tasks](https://arxiv.org/pdf/2305.14552.pdf) | Nick McKenna | |
| 2023 | ArXiv | [LIMA: Less Is More for Alignment](https://arxiv.org/pdf/2305.11206.pdf) | Chunting Zhou | |
| 2020 | ArXiv | [OVERFITTING OR UNDERFITTING? UNDERSTAND ROBUSTNESS DROP IN ADVERSARIAL TRAINING](https://arxiv.org/pdf/2010.08034.pdf) | Zichao Li | |





## Generalization Capability of the Model
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback](https://arxiv.org/pdf/2312.00849.pdf) | Tianyu Yu | |
| 2023 | ArXiv | [Quantifying Uncertainty with Probabilistic Machine Learning Modeling in Wireless Sensing](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10059612) | Amit Kachroo | |

## Finetuning pre-trained Model
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision](https://arxiv.org/pdf/2312.00849.pdf) | Tzu-Jui Julius Wang | |
| 2023 | ArXiv | [Embedding Hallucination for Few-Shot Language Fine-tuning](https://arxiv.org/pdf/2205.01307.pdf) | Yiren Jian | |
| 2022 | ArXiv | [Teaching models to express their uncertainty in words](https://arxiv.org/pdf/2205.14334.pdf) | Stephanie Lin | |






# Solution for AGI Hallucination

## Language Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2022 | ArXiv | [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf) | Long Ouyang | |
| 2023 | ArXiv | [Faithful Persona-based Conversational Dataset Generation with Large Language Models](https://arxiv.org/pdf/2312.10007.pdf) | Pegah Jandaghi | |
| 2023 | ArXiv | [SpecInfer: Accelerating Generative Large Language Model Serving with Speculative Inference and Token Tree Verification](https://arxiv.org/pdf/2305.09781.pdf) | Xupeng Miao | |
| 2023 | ArXiv | [Post Hoc Explanations of Language Models Can Improve Language Models](https://arxiv.org/pdf/2305.11426.pdf) | Satyapriya Krishna | |
| 2023 | ArXiv | [ARE LARGE LANGUAGE MODELS POST HOC EXPLAINERS?](https://arxiv.org/pdf/2310.05797.pdf) | Nicholas Kroeger | |
| 2023 | ArXiv | [TELL YOUR MODEL WHERE TO ATTEND: POST-HOC ATTENTION STEERING FOR LLMS](https://arxiv.org/pdf/2311.02262.pdf) | Qingru Zhang | |
| 2023 | ArXiv | [PERSONALIZED SOUPS: PERSONALIZED LARGE LANGUAGE MODEL ALIGNMENT VIA POST-HOC PARAMETER MERGING](https://arxiv.org/pdf/2310.11564.pdf) | Joel Jang | |






## Video-Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Videochat: Chat-centric video understanding.](https://arxiv.org/pdf/2305.06355.pdf) | KunChang Li | 他们使用Detailed Video Descriptions来减少幻觉，而且引入spatiotemporal reasoning, event localization, 和 causal relationship来丰富video-text语义表达，为未来的研究设定了标准。 |
| 2023 | ArXiv | [Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding](https://arxiv.org/pdf/2311.08046.pdf) | Peng Jin |  首次融合了images和 videos，提出动态visual tokens的概念，使用 high-level 语义特征和low level的视觉细节特征，提出一种Unified方法 |
| 2023 | ArXiv | [Deficiency-Aware Masked Transformer for Video Inpainting](https://arxiv.org/pdf/2307.08629.pdf) | Yongsheng Yu | introduce a dual-modality-compatible inpainting framework called Deficiency-aware Masked Transformer (DMT)，they pretrain a image inpainting model DMTimg serve as a prior for distilling the video model DMTvid, thereby benefiting the hallucination of deficiency cases. |
| 2023 | ArXiv | [Video-LLaMA An Instruction-tuned Audio-Visual Language Model for Video Understanding](https://arxiv.org/pdf/2306.02858.pdf) | Hang Zhang | 本文提出一个 Video Q-former来更好的处理video时序中的理解不一致问题，并使用Audio Q-former进一步捕获音频特征，通过adapter使得多模态和自然语言融合，有效的缓解了幻觉的问题。 |
| 2023 | ArXiv | [Unified Model for Image, Video, Audio and Language Tasks](https://arxiv.org/pdf/2307.16184.pdf) | Mustafa Shukor | This model efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning and they propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-ofdistribution generalization |
| 2022 | ArXiv | [Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue](https://arxiv.org/pdf/2212.05765.pdf) | Sunjae Yoon | 提出了一种 THR 正则损失来减轻幻觉，减轻了 feature-level 幻觉影响，本质上是减少mutual information，从文本特征和图像特征信息层面。|


## 3D Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2019 | CVPR | [Learning 3D Human Dynamics from Video](https://arxiv.org/pdf/2203.15625.pdf) | Angjoo Kanazawa | learn a representation of 3D dynamics of humans from video via a simple but effective temporal encoding of image features which can reduce hallucinations |
| 2023 | ArXiv | [3D-LLM: Injecting the 3D World into Large Language Models](https://arxiv.org/pdf/2307.12981.pdf) | Yining Hong | 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. |
| 2023 | ArXiv | [M3DBench: Let’s Instruct Large Models with Multi-modal 3D Prompts](https://arxiv.org/pdf/2312.10763.pdf) | Mingsheng Li | introduce a comprehensive 3D instruction following dataset called M3DBench, It supports general multimodal instructions interleaved with text, images, 3D objects, and other visual prompts. It unifies diverse 3D tasks at both region and scene levels, covering a variety of fundamental abilities in real-world 3D environments.It is a large-scale 3D instruction-following dataset with over 320k instruction-response pairs. |


## Image-Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [ALIGNING LARGE MULTIMODAL MODELS WITH FACTUALLY AUGMENTED RLHF](https://arxiv.org/pdf/2309.14525.pdf) | Zhiqing Sun | |
| 2023 | ArXiv | [Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites](https://arxiv.org/pdf/2312.01701.pdf) | Lei Wang | |
| 2023 | ArXiv | [Improved Baselines with Visual Instruction Tuning](https://arxiv.org/pdf/2310.03744.pdf) | Haotian Liu | |
| 2017 | ArXiv | [SmoothGrad: removing noise by adding noise](https://arxiv.org/pdf/1706.03825.pdf) | Daniel Smilkov | |
| 2023 | ArXiv | [Mitigating Hallucination in Visual Language Models with Visual Supervision](https://arxiv.org/pdf/2311.16479.pdf) | Zhiyang Chen | |
| 2023 | ArXiv | [ANALYZING AND MITIGATING OBJECT HALLUCINATION IN LARGE VISION-LANGUAGE MODELS](https://arxiv.org/pdf/2310.00754.pdf) | Yiyang Zhou ||




## Robotic & Agent Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | AAAI | [Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/26756) | Ronghui Mu ||
| 2023 | ArXiv | [Audio Visual Language Maps for Robot Navigation](https://arxiv.org/pdf/2303.07522.pdf) | Chenguang Huang ||




# Evaluation for AGI Hallucination


## LLMs
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://arxiv.org/pdf/2305.14251.pdf) | Sewon Min ||
| 2023 | ArXiv | [Generating Benchmarks for Factuality Evaluation of Language Models](https://arxiv.org/pdf/2307.06908.pdf) | Dor Muhlgay ||



## MLLMs
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity](https://arxiv.org/pdf/2302.04023.pdf) | Yejin Bang ||
| 2023 | ArXiv | [AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation](https://arxiv.org/pdf/2311.07397.pdf) | Junyang Wang ||
| 2023 | ArXiv | [A Survey of Hallucination in “Large” Foundation Models](https://arxiv.org/pdf/2309.05922.pdf) | Vipula Rawte ||
| 2023 | ArXiv | [HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models](https://aclanthology.org/2023.emnlp-main.397.pdf) | Junyi Li ||
| 2023 | ArXiv | [Evaluating Object Hallucination in Large Vision-Language Models](https://arxiv.org/pdf/2305.10355.pdf) | Yifan Li ||


## Image-Text Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity](https://arxiv.org/pdf/2302.04023.pdf) | Yejin Bang ||


## Video-Text Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Models See Hallucinations: Evaluating the Factuality in Video Captioning](https://arxiv.org/pdf/2303.02961.pdf) | Hui Liu ||
| 2023 | ArXiv | [VIDEO-CSR: COMPLEX VIDEO DIGEST CREATION FOR VISUAL-LANGUAGE MODELS](https://arxiv.org/pdf/2310.05060.pdf) | Tingkai Liu ||

## 3D Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Evaluating VLMs for Score-Based, Multi-Probe Annotation of 3D Objects](https://arxiv.org/pdf/2311.17851.pdf) | Rishabh Kabra |  |

## Audio Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2020 | ACL | [Asking and Answering Questions to Evaluate the Factual Consistency of Summaries](https://aclanthology.org/2020.acl-main.450.pdf) | Alex Wang |  |



# Discourse for AGI Hallucination
Hallucinations are not always entirely negative phenomena. To a certain extent, they reflect the creativity inherent in the model. We should embrace hallucinations, striving to minimize those that are unequivocally erroneous.


## Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [LLM LIES: HALLUCINATIONS ARE NOT BUGS, BUT FEATURES AS ADVERSARIAL EXAMPLES](https://arxiv.org/pdf/2310.01469.pdf) | Jia-Yu Yao | |
| 2023 | IEEE | [Intentional Biases in LLM Responses](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10316060) |  Nicklaus Badyal | |
| 2023 | ArXiv | [User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination](https://arxiv.org/pdf/2307.16139.pdf) |  Chen Zhang | |






## Image-Text Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization](https://arxiv.org/pdf/2311.16839.pdf) | Zhiyuan Zhao | |
| 2023 | ArXiv | [Iterative Teaching by Data Hallucination](https://arxiv.org/pdf/2210.17467.pdf) | Zeju Qiu | |
| 2023 | ArXiv | [Hallucination Improves the Performance of Unsupervised Visual Representation Learning](https://arxiv.org/pdf/2307.12168.pdf) | Jing Wu| |
| 2023 | ArXiv | [Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination](https://arxiv.org/pdf/2305.12256.pdf) | Hao Fei | |






## Video-Text Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](https://arxiv.org/pdf/2304.14406.pdf) | Sumith Kulal | 本文提出使用人物插入场景的方法，使得模型可以产生人物幻觉和场景幻觉，使得构图协调，又富有创造力。 |
| 2023 | ArXiv | [Multi-Object Tracking with Hallucinated and Unlabeled Videos](https://arxiv.org/pdf/2108.08836.pdf) | Daniel McKee |  |

## Audio Hallucination

| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2023 | ArXiv | [HALLUAUDIO: HALLUCINATE FREQUENCY AS CONCEPTS FOR FEW-SHOT AUDIO CLASSIFICATION](https://arxiv.org/pdf/2302.14204.pdf) | Zhongjie Yu | |

## Robotic & Agent Hallucination
| Year | Source | Name | Author | Content |
| :- | :-: | :- | :- | :- |
| 2021 | ArXiv | [Agile Robot Navigation through Hallucinated Learning and Sober Deployment](https://arxiv.org/pdf/2010.08098.pdf) | Xuesu Xiao ||
| 2021 | ArXiv | [From Agile Ground to Aerial Navigation: Learning from Learned Hallucination](https://arxiv.org/pdf/2108.09793.pdf) | Zizhao Wang ||
| 2023 | ArXiv | [HaLP: Hallucinating Latent Positives for Skeleton-based Self-Supervised Learning of Actions](https://openaccess.thecvf.com/content/CVPR2023/papers/Shah_HaLP_Hallucinating_Latent_Positives_for_Skeleton-Based_Self-Supervised_Learning_of_Actions_CVPR_2023_paper.pdf) | Anshul Shah ||




